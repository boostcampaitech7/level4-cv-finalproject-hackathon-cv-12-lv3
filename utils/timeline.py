import requests
import time
import json
import re
import os
from mtranslate import translate
from api.api_classes import ChatCompletionsExecutor
from config.config import API_CONFIG
import json


def translate_to_english(korean_text):
    """
    í•œê¸€ í‚¤ì›Œë“œë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•˜ëŠ” í•¨ìˆ˜ (API ì—†ì´ ì‘ë™).
    """
    try:
        translated = translate(korean_text, "en", "ko")  # í•œêµ­ì–´ -> ì˜ì–´ ë²ˆì—­
        if not translated.strip():  # ë¹ˆ ë¬¸ìì—´ ë°©ì§€
            raise ValueError("ë²ˆì—­ ê²°ê³¼ê°€ ë¹ˆ ë¬¸ìì—´ì…ë‹ˆë‹¤.")
        return translated
    except Exception as e:
        print(f"âš ï¸ ë²ˆì—­ ì‹¤íŒ¨: {korean_text} â†’ ì›ë˜ ë‹¨ì–´ ìœ ì§€ ({e})")
        return korean_text  # ë²ˆì—­ ì‹¤íŒ¨ ì‹œ ì›ë˜ ë‹¨ì–´ ìœ ì§€


def extract_keywords(text):
    """
    ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì—ì„œ '#'ì´ ì•ì— ë¶™ì€ í‚¤ì›Œë“œë“¤ì„ ë„ì–´ì“°ê¸°ê¹Œì§€ í¬í•¨í•˜ì—¬ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜.
    ì‰¼í‘œê°€ ë‚˜ì˜¤ê¸° ì „ê¹Œì§€ë¥¼ í•˜ë‚˜ì˜ í‚¤ì›Œë“œë¡œ ì¸ì‹í•¨.
    """
    hashtags = re.findall(r"#([^\n#,]+)", text)  # '#' ì´í›„ ì‰¼í‘œ ë˜ëŠ” ì¤„ë°”ê¿ˆ ì „ê¹Œì§€ ì¶”ì¶œ
    keywords = [tag.strip() for tag in hashtags][:4]
    print(f"ì¶”ì¶œëœ ì›ë³¸ í‚¤ì›Œë“œ: {keywords}")
    # í•œê¸€ í‚¤ì›Œë“œ ë³€í™˜
    translated_keywords = [
        translate_to_english(tag) if re.search(r"[ê°€-í£]", tag) else tag
        for tag in keywords
    ]
    return translated_keywords


def timeline_str(query_list):
    # API ì—”ë“œí¬ì¸íŠ¸
    base_url = "https://api.semanticscholar.org/graph/v1/paper/search"

    output_str = ""

    # ê° í‚¤ì›Œë“œë³„ ë…¼ë¬¸ ê²€ìƒ‰
    for query in query_list:
        output_str += f"\nê²€ìƒ‰ í‚¤ì›Œë“œ: {query}\n"
        url = f"{base_url}?query={query}&fields=title,year,citationCount&limit=10"

        response = requests.get(url)

        if response.status_code == 200:
            data = response.json()

            sorted_papers = sorted(
                data.get("data", []), key=lambda x: x["citationCount"], reverse=True)[:3]

            for paper in sorted_papers:
                short_title = paper["title"]
                output_str += f"- {short_title}\n"
                output_str += f"  - ì €ì: {paper['authors'] if 'authors' in paper else 'ì •ë³´ ì—†ìŒ'}\n"
                output_str += f"  - ì¶œíŒ ì—°ë„: {paper['year']}\n"
                output_str += f"  - ì¸ìš© ìˆ˜: {paper['citationCount']}\n"
        else:
            output_str += f"API ìš”ì²­ ì‹¤íŒ¨: {response.status_code}\n"

        # ì†ë„ ì œí•œì„ ê³ ë ¤í•˜ì—¬ 1ì´ˆ ëŒ€ê¸°
        time.sleep(1)

    return output_str




def abstractive_timeline(user_input):
    """
    - ì…ë ¥ëœ í‚¤ì›Œë“œ 4ê°œì— ëŒ€í•´ ê°ê° 3ê°œì˜ ë…¼ë¬¸ì„ ì¶”ì²œ
    - ë…¼ë¬¸ ì œëª©, ì €ì, ì¶œíŒ ì—°ë„, ë…¼ë¬¸ ìš”ì•½, ë‚œì´ë„, ì¶”ì²œ ì´ìœ  í¬í•¨
    - JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
    """
    chat_api = ChatCompletionsExecutor(
        host=API_CONFIG["host"],
        api_key=API_CONFIG["api_key"],
        request_id=API_CONFIG["request_id"],
    )

    system_prompt = """
            ë‹¹ì‹ ì€ ì¸ê³µì§€ëŠ¥ ë° ë¨¸ì‹ ëŸ¬ë‹ ë…¼ë¬¸ ì¶”ì²œì´ì ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
            ë°˜ë“œì‹œ ì•„ë˜ì— ìˆëŠ” ì¤€ìˆ˜í•˜ì—¬ ì¶œë ¥í•´ì£¼ì„¸ìš”.
            ê·¸ì™¸ì˜ ì¶œë ¥ì€ ì˜ëª»ëœ ì¶œë ¥ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
            ì‚¬ìš©ìë¡œë¶€í„° íŠ¹ì • ê²€ìƒ‰ í‚¤ì›Œë“œ 4ê°œë¥¼ ì…ë ¥ë°›ìŠµë‹ˆë‹¤. 
            ì´ ë°ì´í„°ë¥¼ ì°¸ê³ í•˜ì—¬, ê²€ìƒ‰ í‚¤ì›Œë“œ 4ê°œì— ëŒ€í•´ì„œ í‚¤ì›Œë“œë³„ë¡œ ì½ìœ¼ë©´ ì¢‹ì€ ë…¼ë¬¸ì„ ê°ê° 3ê°œ ì°¾ì•„ì„œ ì¶œë ¥í•˜ì„¸ìš”.
            ë‹¨, ë„ˆë¬´ ì˜¤ë˜ëœ ë…¼ë¬¸ì´ë‚˜ ë„ˆë¬´ ìµœì‹ ì˜ ë…¼ë¬¸ì€ ì¶”ì²œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
            **ë°˜ë“œì‹œ 4ê°œì˜ í‚¤ì›Œë“œ ê°ê°ì— ëŒ€í•´ 3ê°œì˜ ë…¼ë¬¸ì„ ì¶”ì²œí•´ì•¼ í•©ë‹ˆë‹¤.**
            
            
            # ğŸ¯ **ìš”êµ¬ì‚¬í•­**
            - **í‚¤ì›Œë“œ 4ê°œë¥¼ ëª¨ë‘ ì²˜ë¦¬í•  ë•Œê¹Œì§€ ë°˜ë³µ ìˆ˜í–‰í•˜ì„¸ìš”.**
            - í‚¤ì›Œë“œë³„ë¡œ ë…¼ë¬¸ì„ ë¶„ë¥˜í•˜ê³ , ê° í‚¤ì›Œë“œì— ëŒ€í•œ í•µì‹¬ ë…¼ë¬¸ì„ **3ê°œì”©** ì¶”ì²œí•˜ì„¸ìš”.
            - ë…¼ë¬¸ ì œëª©, ì €ì, ì¶œíŒ ì—°ë„, ë…¼ë¬¸ ìš”ì•½ì„ í¬í•¨í•˜ì—¬ ì •ë¦¬í•˜ì„¸ìš”.
            - ë…¼ë¬¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶€ì¡±í•  ê²½ìš°, ê´€ë ¨ í‚¤ì›Œë“œ ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ì—¬ ì¶”ì²œí•´ì£¼ì„¸ìš”.
            - ë…¼ë¬¸ì´ ì¤‘ìš”í•œ ì´ìœ  ë˜ëŠ” ì½ì–´ì•¼ í•˜ëŠ” ì´ìœ ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…í•˜ì„¸ìš”.
            - **ë…¼ë¬¸ì˜ ë‚œì´ë„**(ì´ˆê¸‰, ì¤‘ê¸‰, ê³ ê¸‰)ë¥¼ ë¶„ë¥˜í•˜ì—¬ ì¶”ì²œí•˜ì„¸ìš”.
            
            #  **ì¶œë ¥ í˜•ì‹ (JSON ê·œì¹™ ì¤€ìˆ˜)**
            - ë°˜ë“œì‹œ ì¤€ìˆ˜í•  ê²ƒ, í•˜ì§€ë§Œ ì´ëŠ” ì˜ˆì‹œì¼ ë¿ ì¶œë ¥ í˜•ì‹ì„ ì¤€ìˆ˜í•  ê²ƒ
            - í‚¤ì›Œë“œ 4ê°œê°€ ë“¤ì–´ê°€ì•¼ í•˜ë©° ê°ê° 3ê°œì˜ ë…¼ë¬¸ì„ ë°˜ë“œì‹œ ì¶”ì²œí•´ì•¼ í•©ë‹ˆë‹¤.
            - **ì˜¬ë°”ë¥¸ JSONì„ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤** (ì½¤ë§ˆ ëˆ„ë½, ì¤‘ê´„í˜¸ ë‹«í˜ ì˜¤ë¥˜ ë“± ê¸ˆì§€). 
            - JSON ë°ì´í„°ê°€ ê¹¨ì§€ì§€ ì•Šë„ë¡ **ì˜ëª»ëœ ì‰¼í‘œ(,) ì‚½ì… ë°©ì§€** ë° **ì˜¬ë°”ë¥¸ ë°°ì—´ ì¢…ë£Œ(`]`) ìœ ì§€**. 
            - JSON ì´ì™¸ì˜ ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ë‚˜ ì„¤ëª…, ê¸°í˜¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
            - ë¶ˆí•„ìš”í•œ ë¹ˆ í‚¤ì›Œë“œ("í‚¤ì›Œë“œ1": )ë¥¼ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
            - "í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2" ê°™ì€ ìë¦¬í‘œì‹œ(í”Œë ˆì´ìŠ¤í™€ë”) í‚¤ì›Œë“œëŠ” ì¶œë ¥ ì˜ˆì‹œì¼ ë¿ì´ë‹ˆ ì¶œë ¥ì— í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
            - id í‚¤ëŠ” í‚¤ì›Œë“œ ì•ˆ ë…¼ë¬¸ ìˆœì„œëŒ€ë¡œ 1, 2, 3ìœ¼ë¡œ ë§¤ê²¨ì£¼ì„¸ìš”.(ê·¸ë‹¤ìŒ í‚¤ì›Œë“œì—ì„œëŠ” 4,5,6ì´ ì•„ë‹Œ ë‹¤ì‹œ 1,2,3ìœ¼ë¡œ ë§¤ê²¨ì£¼ì„¸ìš”.)
            
            

                  {
                    "Social Capital": [
                        {
                            "id": 1,
                            "ë…¼ë¬¸ ì œëª©": "Social Capital and Social Networks: A Conceptual and Empirical Overview",
                            "ì €ì": "Bourdieu, P.",
                            "ì¶œíŒ ì—°ë„": 2003,
                            "ë…¼ë¬¸ ìš”ì•½": "ì‚¬íšŒ ìë³¸ê³¼ ì‚¬íšŒì  ë„¤íŠ¸ì›Œí¬ì˜ ê°œë…ì , ê²½í—˜ì  ê°œìš”ë¥¼ ì œê³µí•©ë‹ˆë‹¤.",
                            "ë‚œì´ë„": "ì¤‘ê¸‰",
                            "ì¶”ì²œ ì´ìœ ": "ì‚¬íšŒ ìë³¸ ì—°êµ¬ì˜ ê¸°ì´ˆì  ê°œìš”ë¥¼ ì œê³µí•˜ëŠ” ì˜í–¥ë ¥ ìˆëŠ” ë…¼ë¬¸ì…ë‹ˆë‹¤."
                        },
                        {
                            "id": 2,
                            "ë…¼ë¬¸ ì œëª©": "The Strength of Weak Ties: A Network Theory Revisited",
                            "ì €ì": "Granovetter, M. S.",
                            "ì¶œíŒ ì—°ë„": 1973,
                            "ë…¼ë¬¸ ìš”ì•½": "ì•½í•œ ìœ ëŒ€ì˜ ì¤‘ìš”ì„±ê³¼ ì‚¬íšŒ ìë³¸ì—ì„œì˜ ì—­í• ì— ëŒ€í•´ ë…¼ì˜í•©ë‹ˆë‹¤.",
                            "ë‚œì´ë„": "ì´ˆê¸‰",
                            "ì¶”ì²œ ì´ìœ ": "ë„¤íŠ¸ì›Œí¬ ì´ë¡ ì—ì„œ ë„ë¦¬ ì¸ìš©ë˜ëŠ” ë…¼ë¬¸ìœ¼ë¡œ ì•½í•œ ìœ ëŒ€ì˜ ê°œë…ì„ ì„¤ëª…í•©ë‹ˆë‹¤."
                        },
                        {
                            "id": 3,
                            "ë…¼ë¬¸ ì œëª©": "Social Capital: Its Origins and Applications in Modern Sociology",
                            "ì €ì": "Coleman, J. S.",
                            "ì¶œíŒ ì—°ë„": 1988,
                            "ë…¼ë¬¸ ìš”ì•½": "ì‚¬íšŒ ìë³¸ì˜ ê¸°ì›ê³¼ í˜„ëŒ€ ì‚¬íšŒí•™ì—ì„œì˜ ì ìš©ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤.",
                            "ë‚œì´ë„": "ì¤‘ê¸‰",
                            "ì¶”ì²œ ì´ìœ ": "ì‚¬íšŒ ìë³¸ ê°œë…ì„ ì²˜ìŒ ì •ì˜í•˜ê³  ì´ë¥¼ ì‚¬íšŒ í˜„ìƒì— ì ìš©í•œ íšê¸°ì ì¸ ë…¼ë¬¸ì…ë‹ˆë‹¤."
                        }
                    ],
                      
                    "í‚¤ì›Œë“œ2":  [] ,
                    "í‚¤ì›Œë“œ3":  [] ,
                    "í‚¤ì›Œë“œ4":  []
                }
            

            
            # âœ… **ì¶œë ¥ ê²€ì¦**
            - **ì¶œë ¥í•˜ê¸° ì „, ì´ˆë°˜ì— ì…ë ¥ìœ¼ë¡œ ë°›ì•˜ë˜ ê²€ìƒ‰ í‚¤ì›Œë“œ 4ê°œì— ëŒ€í•´ ê°ê° 3ê°œì˜ ë…¼ë¬¸ì •ë³´ê°€ ë“¤ì–´ìˆëŠ”ì§€ ê²€í† í•˜ê³ , ë¹ ëœ¨ë¦° ë¶€ë¶„ì´ ìˆë‹¤ë©´ ê¼­ í˜•ì‹ì— ë§ê²Œ ì±„ì›Œì£¼ê³  ì¶œë ¥í•´ì£¼ì„¸ìš”.
            - **ë˜í•œ ì¶œë ¥ í˜•íƒœë¥¼ ì¤€ìˆ˜í•˜ì˜€ëŠ”ì§€ ê²€í† í•˜ê³  ì¶œë ¥í•´ì•¼í•˜ë©° ì´ì™¸ì˜ ë¶ˆí•„ìš”í•œ ë§ì´ ë“¤ì–´ê°€ ìˆëŠ”ì§€ ê²€í† í•˜ê³  ì¶œë ¥í•´ì£¼ì„¸ìš”.**

            """
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content":  ", ".join(user_input)},
    ]
    request_data = {
        "messages": messages,
        "topP": 0.8,
        "topK": 0,
        "maxTokens": 4096,
        "temperature": 0.6,
        "repeatPenalty": 5.0,
        "stopBefore": [],
        "includeAiFilters": True,
        "seed": 1234,
        "responseFormat": "json"  # ğŸš€ JSON ê°•ì œ ì¶œë ¥ ì„¤ì •
    }
    response = chat_api.execute(request_data, stream=False)
    # full_prompt = f"{system_prompt}\n\nì‚¬ìš©ì ì…ë ¥ í‚¤ì›Œë“œ: {user_input}"
    # # âœ… Gemini API í˜¸ì¶œ
    # model = genai.GenerativeModel(model_name="gemini-pro",
    # generation_config={"response_mime_type": "application/json"})  # JSON ëª¨ë“œ ê°•ì œ)  # ğŸ”¹ Gemini ëª¨ë¸ ì§€ì •
    # response = model.generate_content(full_prompt)
    
    # JSON ë¬¸ìì—´ ì¶”ì¶œ
    response_text = response["message"]["content"]
    
    print(response_text)

    try:
        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
        json_string = extract_json(response_text)

        # JSON ë³€í™˜
        parsed_json = json.loads(json_string)

        # ë³€í™˜ëœ JSON ì €ì¥
        with open("clova_output.json", "w", encoding="utf-8") as f:
            json.dump(parsed_json, f, ensure_ascii=False, indent=4)

        print("âœ… JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: clova_output.json")

    except ValueError as e:
        print(f"âŒ JSON ì¶”ì¶œ ì˜¤ë¥˜ ë°œìƒ: {e}")

    except json.JSONDecodeError as e:
        print(f"âŒ JSON ë³€í™˜ ì˜¤ë¥˜ ë°œìƒ: {e}")

    return parsed_json

def extract_json(response_text):
    """
    Clova ì‘ë‹µì—ì„œ JSON ë°ì´í„°ë§Œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜.
    - JSONì´ ê¹¨ì§ˆ ê°€ëŠ¥ì„±ì„ ë°©ì§€í•˜ê³ , ì •ê·œì‹ìœ¼ë¡œ JSON ë³¸ë¬¸ë§Œ ì¶”ì¶œ.
    """
    json_match = re.search(r'({.*})', response_text, re.DOTALL)
    if json_match:
        return json_match.group(1)  # JSON ë¬¸ìì—´ë§Œ ë°˜í™˜
    else:
        raise ValueError("JSON ì‘ë‹µì„ ê°ì§€í•  ìˆ˜ ì—†ìŒ")